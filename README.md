# ğŸ§© Curve-Fitting Assignment

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Tanish06122004/curve-fitting-assignment/blob/main/Untitled0.ipynb)

---

### ğŸ¯ Assignment Overview
Assignment for **RandD / AI Internship**

Estimate the unknown parameters **Î¸**, **M**, and **X** in the following **parametric equations**:

$$
x(t) = t \cos(\theta) - e^{M|t|} \sin(0.3t)\sin(\theta) + X
$$

$$
y(t) = 42 + t \sin(\theta) + e^{M|t|} \sin(0.3t)\cos(\theta)
$$

for

$$
6 \le t \le 60
$$

---

### ğŸ§® Goal
Find parameters \( \theta, M, X \) that minimize the **L1 distance** between observed and predicted points.

---

### ğŸ§¾ Initial Estimate

If we ignore the sinusoidal term (set it â‰ˆ 0), then:

$$
x \approx t \cos(\theta) + X, \quad y \approx 42 + t \sin(\theta)
$$

Therefore:

$$
y - 42 \approx t \sin(\theta), \quad x - X \approx t \cos(\theta)
$$

Dividing one by the other gives:

$$
\frac{y - 42}{x - X} \approx \tan(\theta)
$$

Thus, \( \theta \) can be estimated by fitting a **linear model** \( y = s x + b \) (ordinary least squares), and setting:

$$
s = \tan(\theta), \quad \theta = \arctan(s)
$$

From the intercept relation:

$$
b = 42 - \tan(\theta) \cdot X \quad \Rightarrow \quad X = \frac{42 - b}{\tan(\theta)}
$$

---

### âš™ï¸ Optimization Procedure

Given current global parameters \( \theta, M, X \):

- For each observed point, find the best-fitting \( t_i \) (bounded to [6, 60]) that minimizes the distance between the observed point and the parametric curve at \( t_i \).  
- Given those \( t_i \), optimize \( \theta, M, X \) to reduce the total L1/L2 residual.  
- Repeat until convergence.

Alternative: run a **global optimizer** (e.g. Differential Evolution) over \( \theta, M, X \), where the inner step estimates \( t_i \) for each candidate parameter set.

---

### ğŸ§  Optimization Objective (L1 Metric)

The assignmentâ€™s scoring is based on the **L1 distance** between uniformly sampled points of expected (observed) and predicted curves:

$$
L_1 = \sum_i \sqrt{(x_{obs,i} - x_{pred,i})^2 + (y_{obs,i} - y_{pred,i})^2}
$$

If the mapping between \( t \) and observed points is unknown, compute for each observed point the minimal distance to the predicted curve â€” or recover \( t \) for each point.

---

### ğŸ§¾ Final Results

| Parameter | Estimated Value |
|------------|-----------------|
| Î¸ (degrees) | **29.9183Â°** |
| M | **0.029925** |
| X | **54.8704** |
| L1 Score | **98.97** |

---

### âœï¸ Final Equation (LaTeX Format)

$$
x(t) = t \cos(0.52307)
- e^{0.029925|t|} \sin(0.3t)\sin(0.52307)
+ 54.8704
$$

$$
y(t) = 42 + t \sin(0.52307)
+ e^{0.029925|t|} \sin(0.3t)\cos(0.52307)
$$

---

### ğŸ“ˆ Visualization 
The fitted curve closely follows the observed data points, confirming accurate parameter estimation.

### ğŸ§© Implementation Details

- **Language:** Python 3  
- **Libraries:** `numpy`, `pandas`, `scipy`, `matplotlib`
- **Environment:** Google Colab  
- **Optimization Method:** L-BFGS-B (bounded minimization)  

---

### ğŸ“˜ Key Equations Summary

1ï¸âƒ£ Linear model:
$$
y = s x + b
$$

2ï¸âƒ£ Angle and offset:
$$
\theta = \arctan(s), \quad X = \frac{42 - b}{\tan(\theta)}
$$

3ï¸âƒ£ L1 Objective:
$$
L_1 = \sum_i |(x_{obs,i} - x_{pred,i})| + |(y_{obs,i} - y_{pred,i})|
$$

---




